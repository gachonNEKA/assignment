## 김다혜's Assignment Submission Status

<br>

| 주차 | 1주차 | 2주차 | 3주차 |
| :---: | :---: | :---: | :---: |
| 제출한 과제 수 | 3/3 | 1/1 | / |

<br>

### 1주차

| 과제 내용 | 과제 파일 링크 | 비고 |
| :---: | :---: | :---: |
| 코드를 돌려보고 결과물 출력 | [Link](https://github.com/dahye411/NEKA_assignment/tree/main/1week) |  |
| 코드 오류 찾기 | [Link](https://github.com/dahye411/NEKA_assignment/tree/main/1week) |  |
| 코드 짜기 | [Link](https://github.com/dahye411/NEKA_assignment/tree/main/1week) |  |

<br>

<b> 과제를 하면서 참고한 것들 </b> :
- pandas axis 매개변수: https://fhaktj8-18.tistory.com/entry/%ED%8C%90%EB%8B%A4%EC%8A%A4-axis-%EB%A7%A4%EA%B0%9C%EB%B3%80%EC%88%98-%EA%B0%9C%EB%85%90-%EC%99%84%EB%B2%BD%EC%A0%95%EB%A6%AC
- torch.rot90: https://pytorch.org/docs/stable/generated/torch.rot90.html, https://jimmy-ai.tistory.com/320
- torch.flip: https://pytorch.org/docs/stable/generated/torch.flip.html
  
<br>

<b> 과제를 하면서 느낀 것 </b> :
2-(1)에서의 df.mean(axis=1)과 3-(2)에서의 회전 축과 뒤집을 축을 인자로 주는 부분을 통해 축의 개념에 대해 자세히 알게 되어서 좋았다.
<br>
<br>

### 2주차

| 과제 내용 | 과제 파일 링크 | 비고 |
| :---: | :---: | :---: |
| 스터디 자료 이해한대로 정리해보기 | [Link](https://github.com/dahye411/NEKA_assignment/tree/main/2week) |  |

<br>

<b> 과제를 하면서 참고한 것들 </b> :
- perceptron: https://heytech.tistory.com/332
- activation function: https://heytech.tistory.com/360
- activation function으로 비선형 함수를 사용하는 이유: https://nongnongai.tistory.com/55
- vanishing gradient: https://heytech.tistory.com/388
- 손실 함수와 경사하강법: https://yhyun225.tistory.com/5
- 순전파, 역전파: https://m.blog.naver.com/jesusss91/221616844641, https://076923.github.io/posts/AI-5/
- overfitting, underfitting: https://22-22.tistory.com/35

<br>

<b> 과제를 하면서 느낀 것 </b> :
인공신경망이 어떠한 방식으로 학습을 하는 지에 대해 여러 자료들을 찾아보며 정리함으로써 개념적 이해를 높일 수 있었다.
<br>
<br>

### 3주차

| 과제 내용 | 과제 파일 링크 | 비고 |
| :---: | :---: | :---: |
|  |  |  |
|  |  |  |
|  |  |  |

<br>

<b> 과제를 하면서 참고한 것들 </b> :

<br>

<b> 과제를 하면서 느낀 것 </b> :


<br>
<br>
